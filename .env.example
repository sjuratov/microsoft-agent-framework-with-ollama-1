# Ollama Configuration (for both CLI and API)
# Base URL for Ollama API
OLLAMA_BASE_URL=http://localhost:11434/v1

# Default model to use for generation
OLLAMA_MODEL_NAME=mistral:latest

# Maximum number of iteration turns (1-10)
OLLAMA_MAX_TURNS=5

# Temperature for generation (0.0-1.0, higher = more creative)
OLLAMA_TEMPERATURE=0.7

# Maximum tokens per generation
OLLAMA_MAX_TOKENS=500

# Request timeout in seconds
OLLAMA_TIMEOUT=30


# API-Specific Configuration (only for REST API)
# Comma-separated list of allowed CORS origins
API_CORS_ORIGINS=http://localhost:3000,http://localhost:8080

# Maximum time allowed for slogan generation in seconds (10 minutes)
API_GENERATION_TIMEOUT=600

# Total request timeout including processing in seconds (10.5 minutes)
API_REQUEST_TIMEOUT=630

# Logging level: DEBUG, INFO, WARNING, ERROR, CRITICAL
API_LOG_LEVEL=WARNING

# Maximum number of concurrent generation requests
API_MAX_CONCURRENT_REQUESTS=10
